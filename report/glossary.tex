% \newglossaryentry{<label>}{<settings>}

% \newacronym[longplural={Frames per Second}]{fpsLabel}{FPS}{Frame per Second}

\newacronym{ubm}{UBM}{universal background model}
\newacronym{gmm}{GMM}{gaussian mixture model}
\newacronym{mfcc}{MFCC}{mel-frequency cepstral coefficients}
\newacronym{hmm}{HMM}{hidden markov model}
\newacronym{plda}{PLDA}{probabilistic linear discriminant analysis}
\newacronym{lda}{LDA}{linear discriminant analysis}
\newacronym{idvc}{IDVC}{inter-dataset variability compensation}
\newacronym{swb}{SWB}{Switchboard}
\newacronym{nap}{NAP}{nuisance attribute projection}
\newacronym{cms}{CMS}{cepstral mean substraction}
\newacronym{wccn}{WCCN}{within-class covariance correction}
\newacronym{eer}{EER}{equal error rate}
\newacronym{mindcf}{minDCF}{minimum decision cost function}
\newacronym{det}{DET}{detection error tradeoff}
\newacronym{vad}{VAD}{voice activity detection}

\longnewglossaryentry{tvm}
{
    name=total variability matrix
}
{
a channel-dependant \gls{gmm} supervector $\bm{M}$ can be modeled as follows

\begin{equation}
\bm{M} = \bm{m} + \bm{T} \bm{w}
\end{equation}

where $\bm{m}$ is a speaker- and channel-independent supervector (the \gls{ubm}
supervector is a good estimate of $\bm{m}$, $\bm{T}$ is a low rank matrix, which
represents a basis of the deduced total variability space and $\bm{w}$ is a
standard normally distributed vector. $\bm{T}$ is the name of the total
variability matrix; the components of $\bm{w}$ are the total factors and they
represent the coordinates of the speaker in the reduced \gls{tvs}. These feature
vectors are referred to as \emph{identity vectors} or \glspl{i-vector} for
short.
}

\newglossaryentry{tvs}
{
    name=total variability space,
    description={lower dimensional space on which \gls{bw-statistics}
        are projected}
}

\newglossaryentry{bw-algorithm}
{
    name=Baum-Welch algorithm,
    description={algorithm used to fit a \gls{hmm}}
}

\newglossaryentry{bw-statistics}
{
    name=Baum-Welch statistics,
    description={emission matrix of a \gls{hmm} fitted by the
        \gls{bw-algorithm}}
}

\newglossaryentry{i-vector}
{
    name=i-vector,
    description={projection of the \gls{bw-statistics} on the \gls{tvs}}
}

\longnewglossaryentry{scatter-matrix}
{
    name=scatter matrix
}
{
A scatter matrix $S$ is a statistic used to make estimates of a covariance
matrix.

In the case of a multivariate normal distribution, $S$ can be written as:

$$S = \sum_{i=1}^n (\bm{x}_i - \bar{\bm{x}})
(\bm{x}_i - \bar{\bm{x}})^t \in \bm{R}^{d \times d}$$

where $n$ is the number of samples, $d$ the number of features, $\bm{x}_i$
are the samples and $\bar{\bm x}$ their mean.

$S$ is positive definite if there exists a subset of the data consisting of $d$
affinely independent observations (which we will assume).
}

\newglossaryentry{utterance}
{
    name=utterance,
    description={speech sequence consisting of one or more words and preceded
                 and followed by silence or a change in speaker}
}
